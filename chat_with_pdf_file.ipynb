{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJeKe38P0B4R",
        "outputId": "51762851-62c6-418b-f142-de39a70c422e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://artifactory.kroger.com/artifactory/api/pypi/pypi-remote/simple\n",
            "Requirement already satisfied: chromadb==0.4.6 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (0.4.6)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /home/krogeradmin/.local/lib/python3.10/site-packages (from chromadb==0.4.6) (0.48.9)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /home/krogeradmin/.local/lib/python3.10/site-packages (from chromadb==0.4.6) (0.23.2)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from chromadb==0.4.6) (0.13.3)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /home/krogeradmin/.local/lib/python3.10/site-packages (from chromadb==0.4.6) (3.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /home/krogeradmin/.local/lib/python3.10/site-packages (from chromadb==0.4.6) (4.8.0)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /home/krogeradmin/.local/lib/python3.10/site-packages (from chromadb==0.4.6) (7.4.0)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from chromadb==0.4.6) (1.23.5)\n",
            "Requirement already satisfied: requests>=2.28 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from chromadb==0.4.6) (2.28.1)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /home/krogeradmin/.local/lib/python3.10/site-packages (from chromadb==0.4.6) (1.16.0)\n",
            "Requirement already satisfied: pydantic<2.0,>=1.9 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from chromadb==0.4.6) (1.10.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /home/krogeradmin/.local/lib/python3.10/site-packages (from chromadb==0.4.6) (4.66.1)\n",
            "Requirement already satisfied: pulsar-client>=3.1.0 in /home/krogeradmin/.local/lib/python3.10/site-packages (from chromadb==0.4.6) (3.3.0)\n",
            "Requirement already satisfied: fastapi<0.100.0,>=0.95.2 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from chromadb==0.4.6) (0.99.1)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.2 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from chromadb==0.4.6) (0.7.2)\n",
            "Requirement already satisfied: importlib-resources in /home/krogeradmin/.local/lib/python3.10/site-packages (from chromadb==0.4.6) (6.1.0)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /home/krogeradmin/.local/lib/python3.10/site-packages (from fastapi<0.100.0,>=0.95.2->chromadb==0.4.6) (0.27.0)\n",
            "Requirement already satisfied: flatbuffers in /home/krogeradmin/.local/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.6) (23.5.26)\n",
            "Requirement already satisfied: sympy in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.6) (1.11.1)\n",
            "Requirement already satisfied: coloredlogs in /home/krogeradmin/.local/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.6) (15.0.1)\n",
            "Requirement already satisfied: protobuf in /home/krogeradmin/.local/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.6) (4.24.3)\n",
            "Requirement already satisfied: packaging in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.6) (22.0)\n",
            "Requirement already satisfied: six>=1.5 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb==0.4.6) (1.16.0)\n",
            "Requirement already satisfied: monotonic>=1.5 in /home/krogeradmin/.local/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb==0.4.6) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /home/krogeradmin/.local/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb==0.4.6) (2.2.1)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb==0.4.6) (2.8.2)\n",
            "Requirement already satisfied: certifi in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from pulsar-client>=3.1.0->chromadb==0.4.6) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from requests>=2.28->chromadb==0.4.6) (1.26.14)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from requests>=2.28->chromadb==0.4.6) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from requests>=2.28->chromadb==0.4.6) (2.0.4)\n",
            "Requirement already satisfied: click>=7.0 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.6) (8.0.4)\n",
            "Requirement already satisfied: h11>=0.8 in /home/krogeradmin/.local/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.6) (0.14.0)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /home/krogeradmin/.local/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.6) (1.0.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /home/krogeradmin/.local/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.6) (0.20.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.6) (6.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /home/krogeradmin/.local/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.6) (11.0.3)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /home/krogeradmin/.local/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.6) (0.6.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/krogeradmin/.local/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.6) (0.17.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /home/krogeradmin/.local/lib/python3.10/site-packages (from starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb==0.4.6) (3.7.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /home/krogeradmin/.local/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.6) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy->onnxruntime>=1.14.1->chromadb==0.4.6) (1.2.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb==0.4.6) (1.2.0)\n",
            "Requirement already satisfied: exceptiongroup in /home/krogeradmin/.local/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb==0.4.6) (1.1.3)\n",
            "Looking in indexes: https://artifactory.kroger.com/artifactory/api/pypi/pypi-remote/simple\n",
            "Requirement already satisfied: pydantic==1.10.9 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (1.10.9)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /home/krogeradmin/.local/lib/python3.10/site-packages (from pydantic==1.10.9) (4.8.0)\n",
            "Looking in indexes: https://artifactory.kroger.com/artifactory/api/pypi/pypi-remote/simple\n",
            "Requirement already satisfied: sentence-transformers in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (2.2.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from sentence-transformers) (2.1.1)\n",
            "Requirement already satisfied: nltk in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from sentence-transformers) (3.7)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from sentence-transformers) (4.24.0)\n",
            "Requirement already satisfied: tqdm in /home/krogeradmin/.local/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\n",
            "Requirement already satisfied: sentencepiece in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from sentence-transformers) (0.1.99)\n",
            "Requirement already satisfied: numpy in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from sentence-transformers) (1.23.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /home/krogeradmin/.local/lib/python3.10/site-packages (from sentence-transformers) (0.16.4)\n",
            "Requirement already satisfied: scipy in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from sentence-transformers) (1.10.0)\n",
            "Requirement already satisfied: scikit-learn in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from sentence-transformers) (1.2.1)\n",
            "Requirement already satisfied: torchvision in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from sentence-transformers) (0.16.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: requests in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/krogeradmin/.local/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.8.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (22.0)\n",
            "Requirement already satisfied: filelock in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.9.0)\n",
            "Requirement already satisfied: fsspec in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2022.11.0)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: sympy in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (11.0.2.54)\n",
            "Requirement already satisfied: networkx in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (2.8.4)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: jinja2 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->sentence-transformers) (12.3.101)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.7.9)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n",
            "Requirement already satisfied: click in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from nltk->sentence-transformers) (8.0.4)\n",
            "Requirement already satisfied: joblib in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from torchvision->sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.1)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.14)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy->torch>=1.6.0->sentence-transformers) (1.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install chromadb==0.4.6\n",
        "!pip install pydantic==1.10.9\n",
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['http_proxy'] = \"http://UID:password@cdcproxy.kroger.com:3128\"\n",
        "os.environ['https_proxy'] = \"http://UID:password@cdcproxy.kroger.com:3128\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDq_JdC70PvB",
        "outputId": "8e780c93-badb-40cc-9e62-ed88c87b06bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://artifactory.kroger.com/artifactory/api/pypi/pypi-remote/simple\n",
            "Requirement already satisfied: langchain in /home/krogeradmin/.local/lib/python3.10/site-packages (0.0.304)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/krogeradmin/.local/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: numpy<2,>=1 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: anyio<4.0 in /home/krogeradmin/.local/lib/python3.10/site-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/krogeradmin/.local/lib/python3.10/site-packages (from langchain) (0.6.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from langchain) (1.10.9)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/krogeradmin/.local/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from langchain) (2.28.1)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.38 in /home/krogeradmin/.local/lib/python3.10/site-packages (from langchain) (0.0.41)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from langchain) (1.4.39)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/krogeradmin/.local/lib/python3.10/site-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/krogeradmin/.local/lib/python3.10/site-packages (from langchain) (3.8.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/krogeradmin/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/krogeradmin/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/krogeradmin/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/krogeradmin/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.2.0)\n",
            "Requirement already satisfied: exceptiongroup in /home/krogeradmin/.local/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.1.3)\n",
            "Requirement already satisfied: idna>=2.8 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from anyio<4.0->langchain) (3.4)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/krogeradmin/.local/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/krogeradmin/.local/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /home/krogeradmin/.local/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (22.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (0.4.3)\n",
            "Looking in indexes: https://artifactory.kroger.com/artifactory/api/pypi/pypi-remote/simple\n",
            "Requirement already satisfied: huggingface_hub in /home/krogeradmin/.local/lib/python3.10/site-packages (0.16.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from huggingface_hub) (6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from huggingface_hub) (22.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /home/krogeradmin/.local/lib/python3.10/site-packages (from huggingface_hub) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from huggingface_hub) (2022.11.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/krogeradmin/.local/lib/python3.10/site-packages (from huggingface_hub) (4.8.0)\n",
            "Requirement already satisfied: filelock in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from huggingface_hub) (3.9.0)\n",
            "Requirement already satisfied: requests in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from huggingface_hub) (2.28.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.14)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from requests->huggingface_hub) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from requests->huggingface_hub) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from requests->huggingface_hub) (2022.12.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5L-HSp7K1Acw",
        "outputId": "108d1f11-828c-46ba-b199-ae4bc06681b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://artifactory.kroger.com/artifactory/api/pypi/pypi-remote/simple\n",
            "Requirement already satisfied: transformers in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (4.24.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/krogeradmin/.local/lib/python3.10/site-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/krogeradmin/.local/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from transformers) (22.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: requests in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
            "Requirement already satisfied: filelock in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from transformers) (2022.7.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/krogeradmin/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.8.0)\n",
            "Requirement already satisfied: fsspec in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (2022.11.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "#loading the API key\n",
        "import getpass\n",
        "\n",
        "# os.environ['HUGGING_FACE_HUB_API_KEY'] = getpass.getpass('Hugging face api key:')\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Irfew7UE1E0h"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain.chains import ConversationChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0MCj9xx2h6k",
        "outputId": "e418e723-e446-451e-814f-26d426a34f33"
      },
      "outputs": [],
      "source": [
        "repo_id = 'lmsys/fastchat-t5-3b-v1.0'  # has 3B parameters: https://huggingface.co/lmsys/fastchat-t5-3b-v1.0\n",
        "# repo_id = \"google/flan-t5-xxl\"\n",
        "llm = HuggingFaceHub(huggingfacehub_api_token=os.environ[\"HUGGINGFACEHUB_API_TOKEN\"],\n",
        "                     repo_id=repo_id,\n",
        "                     model_kwargs={'temperature':0.8, 'max_length':512})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pjn-7E2j4Tzf"
      },
      "outputs": [],
      "source": [
        "query1 = \"Hi! My name is Sadra. I do have some questions for you\"\n",
        "query2 = \"I live in Cincinnati, OH, USA. Who is the first president?\"\n",
        "query3 = \"What is my name?\"\n",
        "query4 = \"Where do I live?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5g3KXVd4snV"
      },
      "source": [
        "# Conversation buffer memory\n",
        "\n",
        "One of the drawbakc of buffer memory is by increasing the size of the text it takes longer time for the model to process and at the same time there will be limitation for the token size. let first check this converstation buffer memory and then we will see what are the alternatives.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LXFfpP-H4yVV"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "conversation_buf = ConversationChain(\n",
        "    llm = llm,\n",
        "    memory = memory\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Grw8byXH4_kk",
        "outputId": "84534754-24ca-49f7-ea69-96ba52611101"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input:  Hi! My name is Sadra. I do have some questions for you\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"<pad> Hello  Sadra!  I'm  here  to  help  you  with  any  questions  you  have.  How  can  I  assist  you  today?\\n\""
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print('input: ', query1)\n",
        "conversation_buf.predict(input=query1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "K2P6uQJo6tNo",
        "outputId": "1d4f2892-b1ce-43eb-94b9-d956cebd4e07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input:  I live in Cincinnati, OH, USA. Who is the first president?\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'<pad> The  first  president  of  the  United  States  was  George  Washington.  He  was  elected  on  January  4,  1789,  and  served  from  1789  to  1797.\\n'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print('input: ', query2)\n",
        "conversation_buf.predict(input=query2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ju4X2o3P7wAp",
        "outputId": "f1c1becb-511d-4245-b522-850ef344a159"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': \"Human: Hi! My name is Sadra. I do have some questions for you\\nAI: <pad> Hello  Sadra!  I'm  here  to  help  you  with  any  questions  you  have.  How  can  I  assist  you  today?\\n\\nHuman: I live in Cincinnati, OH, USA. Who is the first president?\\nAI: <pad> The  first  president  of  the  United  States  was  George  Washington.  He  was  elected  on  January  4,  1789,  and  served  from  1789  to  1797.\\n\"}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "1fT15NOi8Dj1",
        "outputId": "282b55ca-0031-48f7-98c0-c5ca24baa439"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input:  What is my name?\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'<pad>`< pad>  Your  name  is  Sadra.\\n'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"input: \",query3)\n",
        "conversation_buf.predict(input=query3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "eVH9pX4o_HLq",
        "outputId": "e92dc32b-24bb-4270-acb0-bb97d08d2da7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input:  Where do I live?\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'<pad>`< pad>\\n < pad>  You  live  in  Cincinnati,  Ohio,  USA.\\n'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"input: \",query4)\n",
        "conversation_buf.predict(input=query4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEcmdGiN_NQ4",
        "outputId": "a32aaf05-7031-4a51-ff39-affaa055478e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Human: Hi! My name is Sadra. I do have some questions for you\n",
            "AI: <pad> Hello  Sadra!  I'm  here  to  help  you  with  any  questions  you  have.  How  can  I  assist  you  today?\n",
            "\n",
            "Human: I live in Cincinnati, OH, USA. Who is the first president?\n",
            "AI: <pad> The  first  president  of  the  United  States  was  George  Washington.  He  was  elected  on  January  4,  1789,  and  served  from  1789  to  1797.\n",
            "\n",
            "Human: What is my name?\n",
            "AI: <pad>`< pad>  Your  name  is  Sadra.\n",
            "\n",
            "Human: Where do I live?\n",
            "AI: <pad>`< pad>\n",
            " < pad>  You  live  in  Cincinnati,  Ohio,  USA.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(memory.buffer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HkAc1W-_UOF"
      },
      "source": [
        "## Conversation Buffer Window Memory\n",
        "\n",
        "Due to limitiation in term of storage of number of Token for longer conversation in the buffer memory we use another conversation class called buffer window memory. In this buffer window memory we can specify the number of converstaion history we want to keep in the memory. using K tell how many conversaton to keep.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7DpJ3sq-_axv"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "y6DaJSyQA1u7"
      },
      "outputs": [],
      "source": [
        "memory2 = ConversationBufferWindowMemory(k=4)\n",
        "conversation_buf2 = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=memory2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "u2iZH5hiClJX",
        "outputId": "c3ea9376-8ad4-4ad2-9c44-fa14873cb9ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input:  Hi! My name is Sadra. I do have some questions for you\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"<pad> Hello  Sadra!  I'm  here  to  help  you  with  any  questions  you  have.  How  can  I  assist  you  today?\\n\""
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"input: \",query1)\n",
        "conversation_buf2.predict(input=query1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "X_n1YFDfCn2m",
        "outputId": "80fdd43f-d6e2-4e9a-a20e-17cb846f9742"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input:  I live in Cincinnati, OH, USA. Who is the first president?\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'<pad> The  first  president  of  the  United  States  was  George  Washington.  He  was  elected  on  January  4,  1789,  and  served  from  1789  to  1797.\\n'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"input: \",query2)\n",
        "conversation_buf2.predict(input=query2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "lJlXzeqmCt1L",
        "outputId": "68d492a3-d08f-4d92-ffc6-7dfa534c4acc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input:  What is my name?\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'<pad>`< pad>  Your  name  is  Sadra.\\n'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"input: \",query3)\n",
        "conversation_buf2.predict(input=query3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-4Zm5VfDvdP",
        "outputId": "c8cba475-fd7e-49b2-9974-a63c9b595edc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Human: Hi! My name is Sadra. I do have some questions for you\n",
            "AI: <pad> Hello  Sadra!  I'm  here  to  help  you  with  any  questions  you  have.  How  can  I  assist  you  today?\n",
            "\n",
            "Human: I live in Cincinnati, OH, USA. Who is the first president?\n",
            "AI: <pad> The  first  president  of  the  United  States  was  George  Washington.  He  was  elected  on  January  4,  1789,  and  served  from  1789  to  1797.\n",
            "\n",
            "Human: What is my name?\n",
            "AI: <pad>`< pad>  Your  name  is  Sadra.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(memory2.buffer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTmHe0dCD4Z2"
      },
      "source": [
        "# Conversatin Summary memory\n",
        "\n",
        "if do not want to restrict it the number of conversation but instead to the length of the converstation thread that we want to present. we specify token limit.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-YeRlvt1D3Gj"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationSummaryBufferMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "0DBJf6CEEuS9"
      },
      "outputs": [],
      "source": [
        "memory3 = ConversationSummaryBufferMemory(llm=llm, max_token_limit=80)\n",
        "conversation_buf3 = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=memory3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181,
          "referenced_widgets": [
            "498a303c83dd41ef80b0ae13b7c73b86",
            "6f0359202c974d39a1df94c0dd99cdc8",
            "ca40bcd1083c498085c832243f43c976",
            "d4bb3ede73f94cee9c880472ffa3a6b3",
            "279fc4e9213f44d7958b1a1aaa4ad672",
            "a4a9f73bdda14844bdc78ff4a6924dd5",
            "35fafcf8ed1b42d09718a6b158ff1b38",
            "3e524d5234ef411aa6b05311872db7a5",
            "8c271d2190e340b7916bfb5c8373df9b",
            "0b6e3f20ecd24759b599d3726c94f1b0",
            "7ca3cbd2c86646bea90c4900f5316113",
            "af9ee0b2d2f8496dbc26470a1c4c9ebf",
            "30f7540c19fc4961ae89d8b8c13ec7c4",
            "5263bc7c5d7047ef904159e480c90dea",
            "29c2977245984742b7369d549ab715ec",
            "8b8bf49c92ee471aadc66c1e6dd85fd2",
            "db14666176dd4171bb12adbabbf02d6d",
            "9055f0f605e3485b95aca561f40a68bc",
            "8253d37498864cf68917fdaa2b1daeff",
            "df0076b74e4240fd9d3df39ef537e2a6",
            "1fdc8972ddd94a40b62e6ebc749abb94",
            "9002597d1f09446a87516b68eed54451",
            "96481ea0a434448982457569081f12b9",
            "1bfae89e8c59476c97daaec29305ee6e",
            "41485704218c4222a6bc8d0b697d03ef",
            "87f0248697224e5cbe0a54d285248c77",
            "cc7316a6829a4423882368b17a7e3dec",
            "6a091347da554b609fbf8bb37f21c9df",
            "e41928f84acc436186e07a801a45989c",
            "b0681e53a62642b5b45db43e5a063003",
            "7831cfe1ff2842aca4bce4c15b89a19d",
            "9c1c088175f549d9892e540843ccef7e",
            "21a12da5e496422d8cee4339c945d3a9",
            "4c8e5b2ca96f4b57ad75618770a52559",
            "0ac51a5fe777418a9b77f8168679e51c",
            "682aff978ec44bf8b5f5ca1ddd27acd1",
            "b4c5fd61d2c84a74b6454c1cea4c6437",
            "0ac420be9c174fa6a95376e2b9465f2b",
            "b95545d3bc354063bb594528c9f1dc05",
            "e611826d3a3247a4905b8f54569f5215",
            "e4329ad8f6144837bdb2e62c9b85f9a9",
            "1cd9311381f24beb86cddec4da947f5e",
            "6feb4c40101b4165a8108a7f454cf682",
            "3c75510723a247c182559296b52578ca"
          ]
        },
        "id": "rNTtRsNoE4gj",
        "outputId": "3cd5fc77-97c0-48ef-9c05-400f8b1af810"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input:  Hi! My name is Sadra. I do have some questions for you\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"<pad> Hello  Sadra!  I'm  here  to  help  you  with  any  questions  you  have.  How  can  I  assist  you  today?\\n\""
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print('input: ', query1)\n",
        "conversation_buf3.predict(input=query1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ZWLrcxKcFS0N",
        "outputId": "50023ab6-9f2e-4676-de0f-4621496bd546"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input:  I live in Cincinnati, OH, USA. Who is the first president?\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'<pad> The  first  president  of  the  United  States  was  George  Washington.  He  was  elected  on  January  4,  1789,  and  served  from  1789  to  1797.\\n'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"input: \",query2)\n",
        "conversation_buf3.predict(input=query2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1s3GNxoFspL"
      },
      "source": [
        "# Chat PDF with Memory\n",
        "\n",
        "Updated version of Pydantic package (dependency of chromadb) has changed leaving chromadb, incompatible: here are the possible solutions: import error chromadb || Install specific versions of chromadb and pydantic while the bug is resolved\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VvnTVyrFr1K",
        "outputId": "bdf8c7e8-be6c-41ed-9d71-628d0ee017e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Looking in indexes: https://artifactory.kroger.com/artifactory/api/pypi/pypi-remote/simple\n",
            "Requirement already satisfied: pypdf in /home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages (3.17.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "QLtl-z8oGIJQ"
      },
      "outputs": [],
      "source": [
        "import langchain\n",
        "import chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "nUxpuDKBGPDD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "from langchain.document_loaders import PyPDFLoader #document loader: https://python.langchain.com/docs/modules/data_connection/document_loaders\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter #document transformer: text splitter for chunking\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.vectorstores import Chroma # vector store\n",
        "from langchain.llms import HuggingFaceHub ## model hub\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "from langchain.memory import ConversationBufferMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "o0LwWwmOjpDM"
      },
      "outputs": [],
      "source": [
        "## loading the API key\n",
        "import getpass\n",
        "import os\n",
        "# os.environ['HUGGING_FACE_HUB_API_KEY'] = getpass.getpass('Hugging face api key:')\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "fO6bOBuykEWI"
      },
      "outputs": [],
      "source": [
        "# path = input(\"Enter PDF file path: \")\n",
        "path = '/home/krogeradmin/Documents/MSA/LangChain/lmsys_fastchat-t5-3b-v1.0/pdfpath/big_data_clustering.pdf'\n",
        "loader = PyPDFLoader(path)\n",
        "pages = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBVvC_ibkpxa",
        "outputId": "f37332b8-0833-4e99-8ddc-067d9a65eb80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "orl7iAOAmAhf"
      },
      "outputs": [],
      "source": [
        "splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=200)\n",
        "docs = splitter.split_documents(pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "WXYmOA4EmU-N"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/krogeradmin/.conda/envs/Langchain2/lib/python3.10/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
            "  return torch._C._cuda_getDeviceCount() > 0\n"
          ]
        }
      ],
      "source": [
        "embeddings = HuggingFaceEmbeddings()\n",
        "doc_search = Chroma.from_documents(docs, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ZwYQ62XWmmdS"
      },
      "outputs": [],
      "source": [
        "query = 'what is Apache Spark'\n",
        "similar_docs = doc_search.similarity_search(query, k=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXSu3eVtnWUu",
        "outputId": "0ff52acb-cae0-4153-c8f3-6bc01c942ffd"
      },
      "outputs": [],
      "source": [
        "# repo_id = 'lmsys/fastchat-t5-3b-v1.0'  # has 3B parameters: https://huggingface.co/lmsys/fastchat-t5-3b-v1.0\n",
        "repo_id = \"google/flan-t5-xxl\"\n",
        "llm = HuggingFaceHub(huggingfacehub_api_token=os.environ[\"HUGGINGFACEHUB_API_TOKEN\"],\n",
        "                     repo_id=repo_id,\n",
        "                     model_kwargs={'temperature':0.7, 'max_length':512})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "mmQcosS0pUc8"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"\n",
        "Use the following context (delimited by <ctx></ctx>) and the chat history (delimited by <hs></hs>) to answer the question:\n",
        "------\n",
        "<ctx>\n",
        "{context}\n",
        "</ctx>\n",
        "------\n",
        "<hs>\n",
        "{history}\n",
        "</hs>\n",
        "------\n",
        "{question}\n",
        "Answer:\n",
        "\"\"\"\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"history\", \"context\", \"question\"],\n",
        "    template=template,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "8YZeHV2xpW17"
      },
      "outputs": [],
      "source": [
        "memory = ConversationBufferMemory(\n",
        "    memory_key=\"history\",\n",
        "    input_key=\"question\"\n",
        ")\n",
        "\n",
        "retrieval_chain = RetrievalQA.from_chain_type(llm,\n",
        "                                              chain_type='stuff',\n",
        "                                              retriever=doc_search.as_retriever(),\n",
        "                                              chain_type_kwargs={\n",
        "                                                  \"prompt\": prompt,\n",
        "                                                  \"memory\": memory\n",
        "                                              })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "9ODNyiuyqEqs",
        "outputId": "eb131e37-8b0b-4730-b309-e960e9fd30b2"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/krogeradmin/Documents/MSA/LangChain/lmsys_fastchat-t5-3b-v1.0/chat_with_pdf_file.ipynb Cell 42\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Badmindgx1/home/krogeradmin/Documents/MSA/LangChain/lmsys_fastchat-t5-3b-v1.0/chat_with_pdf_file.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m query \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mwhat is spark core\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Badmindgx1/home/krogeradmin/Documents/MSA/LangChain/lmsys_fastchat-t5-3b-v1.0/chat_with_pdf_file.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m retrieval_chain\u001b[39m.\u001b[39;49mrun(query)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/chains/base.py:487\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    486\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 487\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m], callbacks\u001b[39m=\u001b[39;49mcallbacks, tags\u001b[39m=\u001b[39;49mtags, metadata\u001b[39m=\u001b[39;49mmetadata)[\n\u001b[1;32m    488\u001b[0m         _output_key\n\u001b[1;32m    489\u001b[0m     ]\n\u001b[1;32m    491\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    492\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks, tags\u001b[39m=\u001b[39mtags, metadata\u001b[39m=\u001b[39mmetadata)[\n\u001b[1;32m    493\u001b[0m         _output_key\n\u001b[1;32m    494\u001b[0m     ]\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/chains/base.py:292\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    291\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 292\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    293\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    294\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    295\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    296\u001b[0m )\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/chains/base.py:286\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    279\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    280\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m    281\u001b[0m     inputs,\n\u001b[1;32m    282\u001b[0m     name\u001b[39m=\u001b[39mrun_name,\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    284\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    285\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 286\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    287\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    288\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    289\u001b[0m     )\n\u001b[1;32m    290\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    291\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/chains/retrieval_qa/base.py:139\u001b[0m, in \u001b[0;36mBaseRetrievalQA._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_docs(question)  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcombine_documents_chain\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m    140\u001b[0m     input_documents\u001b[39m=\u001b[39;49mdocs, question\u001b[39m=\u001b[39;49mquestion, callbacks\u001b[39m=\u001b[39;49m_run_manager\u001b[39m.\u001b[39;49mget_child()\n\u001b[1;32m    141\u001b[0m )\n\u001b[1;32m    143\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_source_documents:\n\u001b[1;32m    144\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key: answer, \u001b[39m\"\u001b[39m\u001b[39msource_documents\u001b[39m\u001b[39m\"\u001b[39m: docs}\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/chains/base.py:492\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(args[\u001b[39m0\u001b[39m], callbacks\u001b[39m=\u001b[39mcallbacks, tags\u001b[39m=\u001b[39mtags, metadata\u001b[39m=\u001b[39mmetadata)[\n\u001b[1;32m    488\u001b[0m         _output_key\n\u001b[1;32m    489\u001b[0m     ]\n\u001b[1;32m    491\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m--> 492\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks, tags\u001b[39m=\u001b[39;49mtags, metadata\u001b[39m=\u001b[39;49mmetadata)[\n\u001b[1;32m    493\u001b[0m         _output_key\n\u001b[1;32m    494\u001b[0m     ]\n\u001b[1;32m    496\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    497\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    498\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    499\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m but none were provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    500\u001b[0m     )\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/chains/base.py:292\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    291\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 292\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    293\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    294\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    295\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    296\u001b[0m )\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/chains/base.py:286\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    279\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    280\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m    281\u001b[0m     inputs,\n\u001b[1;32m    282\u001b[0m     name\u001b[39m=\u001b[39mrun_name,\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    284\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    285\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 286\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    287\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    288\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    289\u001b[0m     )\n\u001b[1;32m    290\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    291\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/chains/combine_documents/base.py:105\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[1;32m    104\u001b[0m other_keys \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key}\n\u001b[0;32m--> 105\u001b[0m output, extra_return_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcombine_docs(\n\u001b[1;32m    106\u001b[0m     docs, callbacks\u001b[39m=\u001b[39;49m_run_manager\u001b[39m.\u001b[39;49mget_child(), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mother_keys\n\u001b[1;32m    107\u001b[0m )\n\u001b[1;32m    108\u001b[0m extra_return_dict[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key] \u001b[39m=\u001b[39m output\n\u001b[1;32m    109\u001b[0m \u001b[39mreturn\u001b[39;00m extra_return_dict\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/chains/combine_documents/stuff.py:171\u001b[0m, in \u001b[0;36mStuffDocumentsChain.combine_docs\u001b[0;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_inputs(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    170\u001b[0m \u001b[39m# Call predict on the LLM.\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm_chain\u001b[39m.\u001b[39;49mpredict(callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs), {}\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/chains/llm.py:257\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, callbacks: Callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    243\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \n\u001b[1;32m    245\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 257\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key]\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/chains/base.py:292\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    291\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 292\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    293\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    294\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    295\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    296\u001b[0m )\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/chains/base.py:286\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    279\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    280\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m    281\u001b[0m     inputs,\n\u001b[1;32m    282\u001b[0m     name\u001b[39m=\u001b[39mrun_name,\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    284\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    285\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 286\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    287\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    288\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    289\u001b[0m     )\n\u001b[1;32m    290\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    291\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/chains/llm.py:93\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\n\u001b[1;32m     89\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     90\u001b[0m     inputs: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m     91\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     92\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m---> 93\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate([inputs], run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m     94\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_outputs(response)[\u001b[39m0\u001b[39m]\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/chains/llm.py:103\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m    102\u001b[0m prompts, stop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_prompts(input_list, run_manager\u001b[39m=\u001b[39mrun_manager)\n\u001b[0;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[1;32m    104\u001b[0m     prompts,\n\u001b[1;32m    105\u001b[0m     stop,\n\u001b[1;32m    106\u001b[0m     callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    107\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm_kwargs,\n\u001b[1;32m    108\u001b[0m )\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/llms/base.py:504\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[1;32m    497\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    498\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    502\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    503\u001b[0m     prompt_strings \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_string() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[0;32m--> 504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_strings, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/llms/base.py:653\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    639\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    640\u001b[0m         )\n\u001b[1;32m    641\u001b[0m     run_managers \u001b[39m=\u001b[39m [\n\u001b[1;32m    642\u001b[0m         callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[1;32m    643\u001b[0m             dumpd(\u001b[39mself\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m         )\n\u001b[1;32m    652\u001b[0m     ]\n\u001b[0;32m--> 653\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_helper(\n\u001b[1;32m    654\u001b[0m         prompts, stop, run_managers, \u001b[39mbool\u001b[39;49m(new_arg_supported), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    655\u001b[0m     )\n\u001b[1;32m    656\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n\u001b[1;32m    657\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing_prompts) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/llms/base.py:541\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n\u001b[1;32m    540\u001b[0m         run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 541\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    542\u001b[0m flattened_outputs \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m    543\u001b[0m \u001b[39mfor\u001b[39;00m manager, flattened_output \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(run_managers, flattened_outputs):\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/llms/base.py:528\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_generate_helper\u001b[39m(\n\u001b[1;32m    519\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    520\u001b[0m     prompts: List[\u001b[39mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    525\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    526\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    527\u001b[0m         output \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 528\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[1;32m    529\u001b[0m                 prompts,\n\u001b[1;32m    530\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    531\u001b[0m                 \u001b[39m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    532\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[\u001b[39m0\u001b[39;49m] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    533\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    534\u001b[0m             )\n\u001b[1;32m    535\u001b[0m             \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    536\u001b[0m             \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop)\n\u001b[1;32m    537\u001b[0m         )\n\u001b[1;32m    538\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    539\u001b[0m         \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/llms/base.py:1048\u001b[0m, in \u001b[0;36mLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1045\u001b[0m new_arg_supported \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39msignature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1046\u001b[0m \u001b[39mfor\u001b[39;00m prompt \u001b[39min\u001b[39;00m prompts:\n\u001b[1;32m   1047\u001b[0m     text \u001b[39m=\u001b[39m (\n\u001b[0;32m-> 1048\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(prompt, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1049\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m   1050\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(prompt, stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1051\u001b[0m     )\n\u001b[1;32m   1052\u001b[0m     generations\u001b[39m.\u001b[39mappend([Generation(text\u001b[39m=\u001b[39mtext)])\n\u001b[1;32m   1053\u001b[0m \u001b[39mreturn\u001b[39;00m LLMResult(generations\u001b[39m=\u001b[39mgenerations)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/llms/huggingface_hub.py:110\u001b[0m, in \u001b[0;36mHuggingFaceHub._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m _model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_kwargs \u001b[39mor\u001b[39;00m {}\n\u001b[1;32m    109\u001b[0m params \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_model_kwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs}\n\u001b[0;32m--> 110\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient(inputs\u001b[39m=\u001b[39;49mprompt, params\u001b[39m=\u001b[39;49mparams)\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m response:\n\u001b[1;32m    112\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError raised by inference API: \u001b[39m\u001b[39m{\u001b[39;00mresponse[\u001b[39m'\u001b[39m\u001b[39merror\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/inference_api.py:190\u001b[0m, in \u001b[0;36mInferenceApi.__call__\u001b[0;34m(self, inputs, params, data, raw_response)\u001b[0m\n\u001b[1;32m    187\u001b[0m     payload[\u001b[39m\"\u001b[39m\u001b[39mparameters\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m params\n\u001b[1;32m    189\u001b[0m \u001b[39m# Make API call\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m response \u001b[39m=\u001b[39m get_session()\u001b[39m.\u001b[39;49mpost(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapi_url, headers\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheaders, json\u001b[39m=\u001b[39;49mpayload, data\u001b[39m=\u001b[39;49mdata)\n\u001b[1;32m    192\u001b[0m \u001b[39m# Let the user handle the response\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[39mif\u001b[39;00m raw_response:\n",
            "File \u001b[0;32m~/.conda/envs/Langchain2/lib/python3.10/site-packages/requests/sessions.py:635\u001b[0m, in \u001b[0;36mSession.post\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\u001b[39mself\u001b[39m, url, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, json\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    625\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a POST request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \n\u001b[1;32m    627\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 635\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, data\u001b[39m=\u001b[39;49mdata, json\u001b[39m=\u001b[39;49mjson, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/.conda/envs/Langchain2/lib/python3.10/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
            "File \u001b[0;32m~/.conda/envs/Langchain2/lib/python3.10/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:63\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Catch any RequestException to append request id to the error message for debugging.\"\"\"\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     64\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mRequestException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     65\u001b[0m     request_id \u001b[39m=\u001b[39m request\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(X_AMZN_TRACE_ID)\n",
            "File \u001b[0;32m~/.conda/envs/Langchain2/lib/python3.10/site-packages/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    490\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    491\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    492\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    493\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    494\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    496\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    497\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    498\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    499\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    500\u001b[0m         )\n\u001b[1;32m    502\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m\"\u001b[39m):\n",
            "File \u001b[0;32m~/.conda/envs/Langchain2/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/.conda/envs/Langchain2/lib/python3.10/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
            "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "File \u001b[0;32m~/.conda/envs/Langchain2/lib/python3.10/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
            "File \u001b[0;32m~/.conda/envs/Langchain2/lib/python3.10/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1375\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
            "File \u001b[0;32m~/.conda/envs/Langchain2/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
            "File \u001b[0;32m~/.conda/envs/Langchain2/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m~/.conda/envs/Langchain2/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/.conda/envs/Langchain2/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
            "File \u001b[0;32m~/.conda/envs/Langchain2/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "query = 'what is spark core'\n",
        "retrieval_chain.run(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "sYWnOYOLqTtp",
        "outputId": "1eb7be15-03c9-4112-9a49-e238601fd1bf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<pad> The  challenges  of  clustering  big  data  are  characterized  into  three  main  components:\\n 1.  Volume:  as  the  scale  of  the  data  generated  by  modern  technologies  is  rising  exponentially,  clustering  methods  become  computationally  expensive  and  do  not  scale  up  to  very  large  datasets.\\n 2.  High  dimensionality:  clustering  algorithms  must  be  able  to  handle  the  high  dimensionality  of  big  data  by  incorporating  techniques  such  as  feature  selection,  feature  augmentation,  and  feature  selection  techniques.\\n 3.  Complexity:  clustering  algorithms  must  be  able  to  handle  the  complex  nature  of  big  data  by  incorporating  techniques  such  as  feature  selection,  feature  augmentation,  and  feature  selection  techniques.\\n'"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "query = 'Whar are the Challenges of clustering big data'\n",
        "retrieval_chain.run(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1jm94NzvLhO"
      },
      "outputs": [],
      "source": [
        "query = 'who are the authon of Big data clustering techniques based on Spark: a literature review article'\n",
        "retrieval_chain.run(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzBAqfO_qvAv",
        "outputId": "405ec87f-d35a-494c-df76-c6f96d2dc4e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': 'Human: what is spark core\\nAI: \\nHuman: what are the spark components\\nAI: '}"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "memory.load_memory_variables({})"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Langchain2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ac420be9c174fa6a95376e2b9465f2b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ac51a5fe777418a9b77f8168679e51c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b95545d3bc354063bb594528c9f1dc05",
            "placeholder": "​",
            "style": "IPY_MODEL_e611826d3a3247a4905b8f54569f5215",
            "value": "config.json: 100%"
          }
        },
        "0b6e3f20ecd24759b599d3726c94f1b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bfae89e8c59476c97daaec29305ee6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a091347da554b609fbf8bb37f21c9df",
            "placeholder": "​",
            "style": "IPY_MODEL_e41928f84acc436186e07a801a45989c",
            "value": "tokenizer.json: 100%"
          }
        },
        "1cd9311381f24beb86cddec4da947f5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1fdc8972ddd94a40b62e6ebc749abb94": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21a12da5e496422d8cee4339c945d3a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "279fc4e9213f44d7958b1a1aaa4ad672": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29c2977245984742b7369d549ab715ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fdc8972ddd94a40b62e6ebc749abb94",
            "placeholder": "​",
            "style": "IPY_MODEL_9002597d1f09446a87516b68eed54451",
            "value": " 456k/456k [00:00&lt;00:00, 15.3MB/s]"
          }
        },
        "30f7540c19fc4961ae89d8b8c13ec7c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db14666176dd4171bb12adbabbf02d6d",
            "placeholder": "​",
            "style": "IPY_MODEL_9055f0f605e3485b95aca561f40a68bc",
            "value": "merges.txt: 100%"
          }
        },
        "35fafcf8ed1b42d09718a6b158ff1b38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c75510723a247c182559296b52578ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e524d5234ef411aa6b05311872db7a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41485704218c4222a6bc8d0b697d03ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0681e53a62642b5b45db43e5a063003",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7831cfe1ff2842aca4bce4c15b89a19d",
            "value": 1355256
          }
        },
        "498a303c83dd41ef80b0ae13b7c73b86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f0359202c974d39a1df94c0dd99cdc8",
              "IPY_MODEL_ca40bcd1083c498085c832243f43c976",
              "IPY_MODEL_d4bb3ede73f94cee9c880472ffa3a6b3"
            ],
            "layout": "IPY_MODEL_279fc4e9213f44d7958b1a1aaa4ad672"
          }
        },
        "4c8e5b2ca96f4b57ad75618770a52559": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ac51a5fe777418a9b77f8168679e51c",
              "IPY_MODEL_682aff978ec44bf8b5f5ca1ddd27acd1",
              "IPY_MODEL_b4c5fd61d2c84a74b6454c1cea4c6437"
            ],
            "layout": "IPY_MODEL_0ac420be9c174fa6a95376e2b9465f2b"
          }
        },
        "5263bc7c5d7047ef904159e480c90dea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8253d37498864cf68917fdaa2b1daeff",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df0076b74e4240fd9d3df39ef537e2a6",
            "value": 456318
          }
        },
        "682aff978ec44bf8b5f5ca1ddd27acd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4329ad8f6144837bdb2e62c9b85f9a9",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1cd9311381f24beb86cddec4da947f5e",
            "value": 665
          }
        },
        "6a091347da554b609fbf8bb37f21c9df": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f0359202c974d39a1df94c0dd99cdc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4a9f73bdda14844bdc78ff4a6924dd5",
            "placeholder": "​",
            "style": "IPY_MODEL_35fafcf8ed1b42d09718a6b158ff1b38",
            "value": "vocab.json: 100%"
          }
        },
        "6feb4c40101b4165a8108a7f454cf682": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7831cfe1ff2842aca4bce4c15b89a19d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ca3cbd2c86646bea90c4900f5316113": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8253d37498864cf68917fdaa2b1daeff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87f0248697224e5cbe0a54d285248c77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c1c088175f549d9892e540843ccef7e",
            "placeholder": "​",
            "style": "IPY_MODEL_21a12da5e496422d8cee4339c945d3a9",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 10.8MB/s]"
          }
        },
        "8b8bf49c92ee471aadc66c1e6dd85fd2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c271d2190e340b7916bfb5c8373df9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9002597d1f09446a87516b68eed54451": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9055f0f605e3485b95aca561f40a68bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96481ea0a434448982457569081f12b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1bfae89e8c59476c97daaec29305ee6e",
              "IPY_MODEL_41485704218c4222a6bc8d0b697d03ef",
              "IPY_MODEL_87f0248697224e5cbe0a54d285248c77"
            ],
            "layout": "IPY_MODEL_cc7316a6829a4423882368b17a7e3dec"
          }
        },
        "9c1c088175f549d9892e540843ccef7e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4a9f73bdda14844bdc78ff4a6924dd5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af9ee0b2d2f8496dbc26470a1c4c9ebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30f7540c19fc4961ae89d8b8c13ec7c4",
              "IPY_MODEL_5263bc7c5d7047ef904159e480c90dea",
              "IPY_MODEL_29c2977245984742b7369d549ab715ec"
            ],
            "layout": "IPY_MODEL_8b8bf49c92ee471aadc66c1e6dd85fd2"
          }
        },
        "b0681e53a62642b5b45db43e5a063003": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4c5fd61d2c84a74b6454c1cea4c6437": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6feb4c40101b4165a8108a7f454cf682",
            "placeholder": "​",
            "style": "IPY_MODEL_3c75510723a247c182559296b52578ca",
            "value": " 665/665 [00:00&lt;00:00, 24.4kB/s]"
          }
        },
        "b95545d3bc354063bb594528c9f1dc05": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca40bcd1083c498085c832243f43c976": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e524d5234ef411aa6b05311872db7a5",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c271d2190e340b7916bfb5c8373df9b",
            "value": 1042301
          }
        },
        "cc7316a6829a4423882368b17a7e3dec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4bb3ede73f94cee9c880472ffa3a6b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b6e3f20ecd24759b599d3726c94f1b0",
            "placeholder": "​",
            "style": "IPY_MODEL_7ca3cbd2c86646bea90c4900f5316113",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 16.2MB/s]"
          }
        },
        "db14666176dd4171bb12adbabbf02d6d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df0076b74e4240fd9d3df39ef537e2a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e41928f84acc436186e07a801a45989c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4329ad8f6144837bdb2e62c9b85f9a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e611826d3a3247a4905b8f54569f5215": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
